---
title: "Rapport de Projet : Analyse Factorielle Discriminante des Sentiments Twitter"
output: html_document
date: "2026-02-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Le jeu de données "Twitter Entity Sentiment Analysis" comprend des tweets classés par entité (marques, jeux vidéo,...) et par 4 sentiments (Positive, Negative, Neutral, Irrelevant).
L'objectif de ce projet va être de transformer ces données textuelles non structurées en vecteurs numériques afin d'appliquer l'Analyse Factorielle Discriminante (AFD). Nous cherchons à savoir si les caractéristiques lexicales des tweets permettent de séparer distinctement les catégories de de sentiments dans un espace de dimension réduite.

## Phase 1 : Chargement et pré-traitement des données

La première partie consiste en la préparation des données. Sans un nettoyage rigoureux, l'AFD ne produirait que du bruit. 

### 1.1 Les librairies

Tout d'abord, on vient définir les librairies qui vont être utilisés dans l'ensemble du code. Chaque package a un rôle spécifique pour transformer du texte brut en données mathématiques : 

- tidyverse : La base pour manipuler les données.
- textclean/tm : Des outils spécialisés dans le nettoyage de texte.
- SnowballC : Utilisé pour le stemming.
- text2vec : Un package très performant pour transformer le texte en vecteurs numériques.
- MASS : Contient la fonction lda(), c'est le moteur de l'AFD.
- Matrix : Permet de gérer les "matrices creuses", ce qui économise énormément de mémoire vive.
- ggplot2 : Utilisé pour visualiser nos résultats à travers des graphiques, schémas,...

```{r, echo=TRUE}
library(tidyverse)
library(textclean)
library(tm)
library(SnowballC)
library(text2vec)
library(MASS)  
library(Matrix)
library(ggplot2)
```

### 1.2 Chargement

Nous chargeons nos fichiers CSV grâce à la fonction read_csv(). On définit nos paramètres de tel sorte à ce qui R ne convertit pas en catégorie et remplissent les case vides en NA pour "Not available". 
On renomme également nos colonnes afin d'avoir une vision plus claire et lisible pour notre code. 

```{r, echo=TRUE}
train <- read.csv("twitter_training.csv", stringsAsFactors = FALSE, na.strings = c("", "NA"), fileEncoding = "UTF-8")
test  <- read.csv("twitter_validation.csv", stringsAsFactors = FALSE, na.strings = c("", "NA"), fileEncoding = "UTF-8")

colnames(train) <- c("id", "Company", "Sentiment", "Tweet")
colnames(test)  <- c("id", "Company", "Sentiment", "Tweet")
```

### 1.3 Nettoyage

C'est ici que l'on vient transformer le tweet humain en une suite de mots exploitables par un algorithme ; c'est-à-dire sans caractère spécial.

```{r, echo=TRUE}
head(train,5)
```

On crée alors la fonction cleaning qui va effectuer ces lignes :

-replace_url(text) : Supprime les liens.


-tolower(text) : Met tout en minuscules


-gsub("[^a-z]", "", text) : Supprime tout ce qui n'est pas une lettre minuscule.


-removeWords(text, stopwords("en")) : Supprime les mots très fréquents qui n'apportent aucun sens


-wordStem(text) : C'est le stemming. On coupe les terminaisons. Par exemple "playing", "plays", "played" deviennent tous "play".


-gsub("\\s+", " ", text) : remplace les espaces multiples par un seul espace. En effet, lors des précédents essais de nettoyage, notre fonction supprimait les espaces entre les mots ou en ajoutait plusieurs autres par derrière. Cela posait problème lors de l'analyse, certains mots n'était plus séparés. Cette tâche assure qu'il ne reste plus de doubles espaces, espaces en trop et retours à la ligne.


-trimws(text) : Enlève les espaces inutiles au début et à la fin.

```{r, echo=TRUE}
# Supprimer NA
train <- train %>% drop_na(Tweet, Sentiment)
test  <- test %>% drop_na(Tweet, Sentiment)

# Fonction de nettoyage robuste
cleaning <- function(text) {
  if (is.na(text) || nchar(text) == 0) return("")
  text <- replace_url(text)
  text <- tolower(text)
  text <- gsub("[^a-z]", " ", text)
  text <- removeWords(text, stopwords("en"))
  text <- wordStem(text)  # stemming
  text <- gsub("\\s+", " ", text)
  text <- trimws(text)
  return(text)
}

train$clean_tweet <- sapply(train$Tweet, cleaning)
test$clean_tweet  <- sapply(test$Tweet, cleaning)

# Supprimer les tweets vides
train <- train[nchar(train$clean_tweet) > 0, ]
test  <- test[nchar(test$clean_tweet) > 0, ]

train$Sentiment <- as.factor(train$Sentiment)
test$Sentiment  <- as.factor(test$Sentiment)
```


### 1.4 Application

On applique la fonction à nos colonnes "Tweet" du CSV training et validation. On utilise la fonction sapply(). 
Très important ! Après avoir supprimé les URLs et les mots vides, certains tweets peuvent devenir totalement vides. Si vous les gardez, l'AFD plantera car elle ne peut pas analyser un tweet sans mots.

Une fois toutes étapes, on transforme la colonne Sentiment en catégories (Positive, Negative, etc.). C'est indispensable pour l'AFD car elle a besoin de savoir quelles sont les "classes" à séparer.


```{r, echo=TRUE}
train$clean_tweet <- sapply(train$Tweet, cleaning)
test$clean_tweet  <- sapply(test$Tweet, cleaning)

# Supprimer les tweets vides après nettoyages + Conversion en catégories
train <- train[nchar(train$clean_tweet) > 0, ]
test  <- test[nchar(test$clean_tweet) > 0, ]

train$Sentiment <- as.factor(train$Sentiment)
test$Sentiment  <- as.factor(test$Sentiment)
```

```{r, echo=TRUE}
head(train,5)
```

## Phase 2 : Ingénierie des caractéristiques

Cette deuxième phase est celle de la vectorisation. Le but est de transformer nos mots nettoyés en nombres pour que l'algorithme de l'AFD puisse effectuer des calculs matriciels. 

### 2.1 Création du vocabulaire

Afin de créer un dictonnaire de données, on va utiliser une méthode de text2vec, s'appelant itoken(). Cette fonction forme un itérateur, qui vient découper nos phrases en unités individuelles et donc, évite de charger tout le texte en mémoire d'un coup.

```{r, echo=TRUE}
it_train <- itoken(train$clean_tweet, progressbar = TRUE)
it_test  <- itoken(test$clean_tweet, progressbar = TRUE)
```


Maintenant, on construit le vocabulaire des tweets.
On prend la fonction prune_vocabulary(), qui ira sélectionner des mots précis, grâce à ses paramètres : 

-term_count_min = n,, qui élimine les mots qui apparaissent moins de n fois. S'ils sont trop rares, ils ne peuvent pas aider à généraliser un sentiment.

-doc_proportion_max = 0.5 : On élimine les mots qui sont présents dans plus de la moitié des tweets (ex: "game", "twitter"). S'ils sont partout, ils ne permttront pas une distiction entre les sentiments. 

-vocab_term_max = 800 : C'est la décision la plus importante. L'AFD ne supporte pas d'avoir trop de colonnes. En limitant à 800 mots, vous vous assurez que le modèle reste calculable et stable.

```{r, echo=TRUE}
vocab <- create_vocabulary(it_train, ngram = c(1, 3))
vocab <- prune_vocabulary(vocab, 
                          term_count_min = 10, 
                          doc_proportion_max = 0.5,
                          vocab_term_max = 800)

vectorizer <- vocab_vectorizer(vocab)
```


P.S. : Le choix du nombres de colonnes est très important pour le bon fonctionnement du code. En effet, en gardant le nombre maximal, on risque de se frotter à 2 erreurs : une instabilité de calcul dans l'AFD ou bien une explosion de la mémoire. 

#### Améliorations

1.1. Lors des premiers tests, On observait que l'accuracy de notre code était très mauvais (~20%). Cela signifie que notre modèle n'a pas pu correctement séparer nos sentiments dans différentes classes. 

Un des raisons est lié à notre liste de vocabulaire : en effet, elle retourne le tweet traité en une longue phrase de lettres collées les unes aux autres, ne facilitant la lecture de la sémantique. 
Cette fois ci, nous allons alors modifier notre fonction "cleaning" afin de pouvoir garder les mots séparées au fois le tratement effectué. Cette action permettra de mieux vectoriser chaque paramètre. En effet, grâce à cette action, notre "accuracy" a pu doubler son pourcentage (~50%) et ainsi, montrer une meilleure AFD. 


1.2. On peut encore faire mieux. Puisque l'on veut faciliter le choix dans le vocabulaire, une étape "intermédiaire" classique pour booster l'AFD consiste à ne pas regarder seulement les mots seuls, mais aussi les paires de mots (bigrammes).
En effet, dans l'analyse des sentiments, on peut avoir les mots individuels "not good" côté à côté, mais considérés comme 2 mots distincts, ce qui fausse nos résultats.

Ainsi on modifie notre paramètre vocab, et ainsi offrir plus de possibilités et combinaisons de champ lexicals. Encore une fois, ce changement a permis une meilleure précision. 

### 2.2 Création des matrices TF-IDF

Le texte est maintenant transformé en une matrice où chaque ligne est un tweet et chaque colonne est un mot du vocabulaire.

On utilise create_dtm pour créer la Document-Term Matrix.
De là, on applique la pondération TF-IDF. Donc : 
-Plus un mot est présent dans un tweet, plus il est important.


-Si un mot est présent dans beaucoup de tweets différents, on diminue son importance car il est banal.


-Un mot comme "excellent" (positif) recevra un score élevé s'il est rare dans le corpus global mais présent dans le tweet analysé.

```{r, echo=TRUE}
dtm_train <- create_dtm(it_train, vectorizer)
dtm_test  <- create_dtm(it_test, vectorizer)

tfidf <- TfIdf$new()
dtm_train_tfidf <- tfidf$fit_transform(dtm_train)
dtm_test_tfidf  <- tfidf$transform(dtm_test)
```

### Conversion

Ici, nous devons convertir nos résultats en une dataFrame puisque l'algorithme lda() du package MASS ne travaille pas avec les objets spécifiques de text2vec.

```{r, echo=TRUE}
X_train <- as.matrix(dtm_train_tfidf)  # attention: déjà creuse, peut rester Matrix
X_test  <- as.matrix(dtm_test_tfidf)

data_train_afd <- data.frame(Sentiment = train$Sentiment, X_train)
data_test_afd  <- data.frame(Sentiment = test$Sentiment, X_test)
```

Et voilà, on obtient les informations nécessaires pour effectuer nos recherches ! 

## Phase 3 : Analyse factorielle discriminante (AFD)

C'est ici que l'Analyse Factorielle Discriminante commence. 

### 3.1 Modèle AFD

On vient chercher un relation entre le Sentiment et toutes les autres colonnes (800 mots de vocabulaire). L'algorithme calcule des vecteurs qui maximisent la séparation entre les groupes (Positive, Negative, etc.). Par exemple, si le mot "bad" apparaît souvent dans le groupe "Négatif" et jamais ailleurs, l'AFD va donner un poids très fort à ce mot pour construire l'axe de séparation.

```{r, echo=TRUE}
lda_model <- lda(Sentiment ~ ., data = data_train_afd)

lda_train <- predict(lda_model, data_train_afd)
lda_test  <- predict(lda_model, data_test_afd)
```

### La projection et dataframe de visualisation

On récupère les nouvelles coordonnées de nos tweets. Au lieu d'être dans un espace complexe à 1000 dimensions (les mots), chaque tweet est maintenant résumé par seulement quelques valeurs : LD1, LD2, LD3.
On crée ensuite  un petit tableau simplifié qui ne contient que les deux premiers axes (LD1 et LD2) et le sentiment réel. C'est ce tableau qui permet de dessiner une carte en 2D de nos données textuelles.

```{r, echo=TRUE}
lda_df_train <- data.frame(
  LD1 = lda_train$x[,1],
  LD2 = lda_train$x[,2],
  Sentiment = data_train_afd$Sentiment
)
```

## Phase 4 : Visualisation

On génère le graphique visuel avec ggplot2(). On place les tweets sur les axes de séparation trouvés par l'AFD.

```{r, echo=TRUE}
p <- ggplot(lda_df_train, aes(x = LD1, y = LD2, color = Sentiment)) +
  geom_point(alpha = 0.6) +
  theme_minimal() +
  labs(
    title = "Projection AFD (LDA) des tweets",
    x = "Axe discriminant 1 (LD1)",
    y = "Axe discriminant 2 (LD2)",
    color = "Sentiment"
  )

p
```


Chaque point représente un tweet. La couleur représente le Sentiment auquel le tweet a été attribué.

==> On peut observer alors une séparation discriminante correcte : on a les tweets "Positive", "Negative" et "Neutral" qui sont majoritairement répartits entre eux. 

==> On observe également que les tweets "Irrelevant" se chevauchent entre les différentes classes. Ceci est un bon indicatif, car les tweets neutres partagent du vocabulaire avec toutes les autres classes, étant donné que les mots utilisés ne sont pas distincts des autres. Ainsi, l’AFD ne peut séparer que ce qui est réellement discriminant dans ces données.

On peut interpréter les 2 axes LD1 et LD2 comme : 

- LD1 : Définit la séparation brute des sentiments (Positif --> Neutral/Irrelevant --> Negative)

- LD2 : Définit l'intensité du sentiment (faible à fort).


On génère un autre graphique visuel avec ggplot2(). On regarde cette fois les distributions des sentiments selon l'axe principal. 

```{r, echo=TRUE}
q <-ggplot(lda_df_train, aes(x = LD1, fill = Sentiment)) +
  geom_density(alpha = 0.5) +
  theme_minimal() +
  labs(title = "Distribution des sentiments sur le premier axe discriminant (LD1)",
       x = "LD1 (Séparateur principal)",
       y = "Densité")

q
```


==> On voit que la courbe "Negative" est isolé du reste des courbes de densité, qui se chevauchent.
- On peut en déduire que le modèle sépare bien les sentiments négatives mais peine à faire la différence entre les deux autres. 

Enfin, on définit une troisème courbe qui vient identifier quels sont les mots les plus discriminants.

```{r, echo=TRUE}
# Extraire les coefficients (scaling)
loadings <- as.data.frame(lda_model$scaling)
loadings$word <- rownames(loadings)

# Top 10 des mots qui influencent le plus LD1 (positif et négatif)
top_words <- loadings %>%
  arrange(desc(abs(LD1))) %>%
  head(20)

r <- ggplot(top_words, aes(x = reorder(word, LD1), y = LD1)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Top 20 des mots les plus discriminants (LD1)",
       x = "Mots", y = "Poids dans l'axe LD1")

r
```

==> 



## Phase 5 : Evaluation du modéle

On fait l'évaluation du modèle AFD. On construit alors la matrice de confusion qui permet de visualiser le nombre de mots de chaque classe face à la prédiction faite par notre modèle. 

```{r, echo=TRUE}
pred_test <- lda_test$class
confusion <- table(Predicted = pred_test, Actual = data_test_afd$Sentiment)
print(confusion)

accuracy <- sum(diag(confusion)) / sum(confusion)
accuracy
```

==> On obtient une accuracy de 62%, ce qui est satisfaisant. On a su pouvoir classer les sentiments basés sur du texte court. Ce chiffre peut augmenter, si le nombre de tweets traités ou le nombre de bigrammes analysés augmentait. 


## Travaux futurs

Ce mini projet pourrait être amélioré et notre analyse plus poussée sur plusieurs points : 

1. Ponctuation expressive : Dans un message écrit, la ponctuation joue un rôle très important dans l'interprétation des sentiments d'un individu. C'est le moyen de communication le plus distinctif, qui fait la différence. Un exemple serait celui-ci : 

- "Génial !" --> Enthousiasme, "Génial..." --> Agaçement, "Génial !?" --> Incompréhension, "Génial." --> Indifférence.

-> Ces petits caractères se révèlent être de grands atouts et facteurs importants pour une analyse des émotions. On peut alors chercher à vouloir les intégrer à notre code, afin d'avoir une meilleure caractérisation des tweets. 

2. Plus de données :Le plus évident serait bien évidemment, d'augmenter la taille des données à analyser. Un tweet est un indicateur d'émotion directe, mais il reste dépendant du contexte dans lequel il est écrit : 

- Quelqu'un peut faire une critique d'un jeu mais pour autant ne pas être négatif, 

- D'autres peuvent utiliser le sarcasme et la ponctuation pour exprimer leur avis, ce qui est difficilement identifiable pour les machines. 

-> Avoir plus de matière et de contexte, comme des avis plus poussés ans la réflexion, aiderait grandement une meilleure compréhension des sentiments.


3. Modèle plus lisse ? : Comme nous le savons, l'analyse discriminative linéaire va chercher des combinaisons linéaires des variables pour séparer les classe. Or bien souvent, un mot ne définit pas forcément l'émotion recherchée. Justement, lorsque nous réalisons les bigrammes, on cherche des ensembles de mots qui permettent de mieux définir les sentiments : 

- "good" --> Positive

- "Not good" --> Negative 

Mais la LDA simple prend les mots individuellement et donc ne capturent pas ces relations sémantiques. 

En questionnant des sites web et les IA de recherche, il existe une alternative nommée SVM ou "Support Vector Machine". C'est un nouveau modèle qui est capable d'apprendre des notions non linéaires. Au delà de ça, elle peut gérer des données à dimension haute et creuses, qualité que ne possède pas LDA. 

-> Je pense alors de modifier notre approche de modélisation pourrait avoir un impact sur la qualité d'analyse du code à l'avenir. 






